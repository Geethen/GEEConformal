{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic World: Uncertainty Quantification\n",
    "This notebooks provides an example of using the conformalImageClassifier class by quantifying uncertainty for the Dynamic World dataset. This dataset contains 9. For each candidate class, a probability band is made readily available.\n",
    "\n",
    "We use the validation data, not used in training the model, to calibrate a conformal classifier and then evaluate the model. Finally, we will use the calibrated classifier to run inference on a new (out-of-sample) image. This will be achieved in five steps.\n",
    "\n",
    "**Step 1**: Load modules  \n",
    "**Step 2**: Prepare Dynamic world data  \n",
    "**Step 3**: Calibrate a conformal classifier  \n",
    "**Step 4**: Evaluate a conformal classifier  \n",
    "**Step 5**: Run inference on a new scene using the calibrated conformal classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "\n",
    "from geeml.utils import eeprint\n",
    "\n",
    "import sys\n",
    "MODULE_FULL_PATH = r'C:\\Users\\coach\\myfiles\\postdoc\\Uncertainty\\code\\GEEConformal\\code'\n",
    "sys.path.insert(1, MODULE_FULL_PATH)\n",
    "\n",
    "from conformalClassifier import conformalImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.13\n",
      "IPython version      : 8.4.0\n",
      "\n",
      "Compiler    : MSC v.1929 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 165 Stepping 2, GenuineIntel\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "sys: 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:50:36) [MSC v.1929 64 bit (AMD64)]\n",
      "ee : 0.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Dynamic World data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single polygon with a global extent\n",
    "globalBounds = ee.Geometry.Polygon([-180, 90, 0, 90, 180, 90, 180, -90, 10, -90, -180, -90], None, False)\n",
    "\n",
    "# List of probability band names\n",
    "bands = ['water', 'trees', 'grass', 'flooded_vegetation',\n",
    "'crops', 'shrub_and_scrub', 'built', 'bare', 'snow_and_ice']\n",
    "\n",
    "# Load dynamic world validation tiles\n",
    "dwl = ee.ImageCollection('projects/nina/GIS_synergy/Extent/DW_global_validation_tiles')\n",
    "dwLabels = dwl.select([1], ['label']).map(lambda img: ee.Image(img.updateMask(# Select reference label band\n",
    "    img.gt(0).And(img.lt(10))).subtract(1).copyProperties(img))# remove unmarked up areas and extra-class\n",
    "    # hacky method to edit image property\n",
    "    .set('joinindex', img.rename(img.getString('system:index')).regexpRename('^[^_]*_', '').bandNames().getString(0)))\\\n",
    "    .randomColumn(**{'seed': 42})# add random column\n",
    "\n",
    "dwp = ee.ImageCollection(\"projects/ee-geethensingh/assets/UQ/DW_probs\")\n",
    "dwp = dwp.map(lambda img: ee.Image(img.rename(bands).selfMask()).copyProperties(img) #rename bands, mask 0 pixels\n",
    "    # Hacky method to edit image property\n",
    "    .set('joinindex', img.select([0]).rename(img.getString('id_no')).regexpRename('^[^_]*_', '').bandNames().getString(0)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join label collection and probability collection on their 'joinindex' property. The propertyName parameter\n",
    "# is the name of the property that references the joined image.\n",
    "def indexJoin(collectionA, collectionB, propertyName):\n",
    "    joined = ee.ImageCollection(ee.Join.saveFirst(propertyName).apply(**{\n",
    "    'primary': collectionA,\n",
    "    'secondary': collectionB,\n",
    "    'condition': ee.Filter.equals(**{\n",
    "      'leftField': 'joinindex',\n",
    "      'rightField': 'joinindex'})\n",
    "      })) \n",
    "    # Merge the bands of the joined image.\n",
    "    return joined.map(lambda image: image.addBands(ee.Image(image.get(propertyName))))\n",
    "\n",
    "dwCombined = indexJoin(dwLabels, dwp, 'probImage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calibrate conformal classifier\n",
    "\n",
    "We use 80% of the image chips for calibrating the conformal classifier and the remaining 20% for evaluating the conformal classifier. Note, the evaluation phase is more compute heavy than the calibration stage. All analyses are performed at the native spatial resolution of dynamic world (10 m). We specify an alpha value of 10% i.e., we can tolerate a 10% error level or in other words we are satisfied if 10% of pixels do not contain the actual label within their prediction sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"54c410f1-1bff-4708-b944-75f4bec72990\" style=\"height: auto; width:100%;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " \n",
       "        <script src=\"/static/components/requirejs/require.js\"></script> <!-- Needed in Colab -->\n",
       "        <script>\n",
       "            require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
       "              renderjson.set_show_to_level(1)\n",
       "              document.getElementById('54c410f1-1bff-4708-b944-75f4bec72990').appendChild(renderjson({\"type\": \"Feature\", \"geometry\": \"None\", \"properties\": {\"qHat\": 0.06061363332802309, \"qLevel\": 9.999998682418095, \"version\": \"demoDW_06012024\"}}))\n",
       "            });\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SCALE = 10 #Used to compute Eval metrics\n",
    "ALPHA = 0.1 #1-ALPHA corresponds to required coverage. For example, 0.1 for 90% coverage\n",
    "SPLIT = 0.95 #Split used for calibration and test data (for example, 0.8 corresponds to 80% calibration data)\n",
    "LABEL = 'label' #Band name for reference label band\n",
    "\n",
    "# Intialise conformal Image classifier\n",
    "cc = conformalImageClassifier(data = dwCombined, scale = SCALE,\n",
    "                            bands = bands, alpha = ALPHA, split = SPLIT,\n",
    "                            label = LABEL, version = 'demoDW_06012024')\n",
    "# Calibrate conformal Image classifier\n",
    "eeprint(cc.calibrate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate conformal classifier\n",
    "During evaluation on the test set, we use two metrics\n",
    "1. The average set size (The sum of the lengths for all prediction sets, divided by the number of test pixels)\n",
    "2. The empirical marginal coverage (The proportion of sets that contain the reference labels)\n",
    "\n",
    "The ideal average set size is 1. A value less than 1 suggests many empty sets while, in this case, a value closer to 9 indicates a statistically inefficient conformal predictor. We have a value of 2.29 which is a rather statistically efficient conformal predictor.\n",
    "\n",
    "The empirical marginal coverage should be close to the the required coverage (0.9 in this case). We have a value of 0.94, which is greater than our required coverage. This suggests that the conformal predictor could be slightly more efficient( have a slightly smaller average set size and still satisfy our required coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average set size: 2.29\n",
      "Empirical (marginal) coverage: 0.94\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"d97b9817-ab60-44ba-9fa8-0cb16f95b293\" style=\"height: auto; width:100%;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " \n",
       "        <script src=\"/static/components/requirejs/require.js\"></script> <!-- Needed in Colab -->\n",
       "        <script>\n",
       "            require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
       "              renderjson.set_show_to_level(1)\n",
       "              document.getElementById('d97b9817-ab60-44ba-9fa8-0cb16f95b293').appendChild(renderjson({\"type\": \"Feature\", \"geometry\": \"None\", \"properties\": {\"Average Prediction Set Size\": 2.293395623327078, \"Empirical Marginal Coverage\": 0.9353167020674085, \"version\": \"demoDW_06012024\"}}))\n",
       "            });\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eeprint(cc.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Inference \n",
    "We quantify uncertainty for an unseen image using a calibrated conformal classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552a8a6aa30d4927bff11c5c58bb7efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.12915465149783, -119.27099079468887], controls=(WidgetControl(options=['position', 'transparentâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        var code = IPython.notebook.insert_cell_below('code');\n        code.set_text(atob(\"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\"));\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vis_params = {'bands': ['setLength'], 'palette': ['#440154', ' #440256', ' #450457', ' #450559', ' #46075a', ' #46085c', ' #460a5d', ' #460b5e', ' #470d60', ' #470e61', ' #471063', ' #471164', ' #471365', ' #481467', ' #481668', ' #481769', ' #48186a', ' #481a6c', ' #481b6d', ' #481c6e', ' #481d6f', ' #481f70', ' #482071', ' #482173', ' #482374', ' #482475', ' #482576', ' #482677', ' #482878', ' #482979', ' #472a7a', ' #472c7a', ' #472d7b', ' #472e7c', ' #472f7d', ' #46307e', ' #46327e', ' #46337f', ' #463480', ' #453581', ' #453781', ' #453882', ' #443983', ' #443a83', ' #443b84', ' #433d84', ' #433e85', ' #423f85', ' #424086', ' #424186', ' #414287', ' #414487', ' #404588', ' #404688', ' #3f4788', ' #3f4889', ' #3e4989', ' #3e4a89', ' #3e4c8a', ' #3d4d8a', ' #3d4e8a', ' #3c4f8a', ' #3c508b', ' #3b518b', ' #3b528b', ' #3a538b', ' #3a548c', ' #39558c', ' #39568c', ' #38588c', ' #38598c', ' #375a8c', ' #375b8d', ' #365c8d', ' #365d8d', ' #355e8d', ' #355f8d', ' #34608d', ' #34618d', ' #33628d', ' #33638d', ' #32648e', ' #32658e', ' #31668e', ' #31678e', ' #31688e', ' #30698e', ' #306a8e', ' #2f6b8e', ' #2f6c8e', ' #2e6d8e', ' #2e6e8e', ' #2e6f8e', ' #2d708e', ' #2d718e', ' #2c718e', ' #2c728e', ' #2c738e', ' #2b748e', ' #2b758e', ' #2a768e', ' #2a778e', ' #2a788e', ' #29798e', ' #297a8e', ' #297b8e', ' #287c8e', ' #287d8e', ' #277e8e', ' #277f8e', ' #27808e', ' #26818e', ' #26828e', ' #26828e', ' #25838e', ' #25848e', ' #25858e', ' #24868e', ' #24878e', ' #23888e', ' #23898e', ' #238a8d', ' #228b8d', ' #228c8d', ' #228d8d', ' #218e8d', ' #218f8d', ' #21908d', ' #21918c', ' #20928c', ' #20928c', ' #20938c', ' #1f948c', ' #1f958b', ' #1f968b', ' #1f978b', ' #1f988b', ' #1f998a', ' #1f9a8a', ' #1e9b8a', ' #1e9c89', ' #1e9d89', ' #1f9e89', ' #1f9f88', ' #1fa088', ' #1fa188', ' #1fa187', ' #1fa287', ' #20a386', ' #20a486', ' #21a585', ' #21a685', ' #22a785', ' #22a884', ' #23a983', ' #24aa83', ' #25ab82', ' #25ac82', ' #26ad81', ' #27ad81', ' #28ae80', ' #29af7f', ' #2ab07f', ' #2cb17e', ' #2db27d', ' #2eb37c', ' #2fb47c', ' #31b57b', ' #32b67a', ' #34b679', ' #35b779', ' #37b878', ' #38b977', ' #3aba76', ' #3bbb75', ' #3dbc74', ' #3fbc73', ' #40bd72', ' #42be71', ' #44bf70', ' #46c06f', ' #48c16e', ' #4ac16d', ' #4cc26c', ' #4ec36b', ' #50c46a', ' #52c569', ' #54c568', ' #56c667', ' #58c765', ' #5ac864', ' #5cc863', ' #5ec962', ' #60ca60', ' #63cb5f', ' #65cb5e', ' #67cc5c', ' #69cd5b', ' #6ccd5a', ' #6ece58', ' #70cf57', ' #73d056', ' #75d054', ' #77d153', ' #7ad151', ' #7cd250', ' #7fd34e', ' #81d34d', ' #84d44b', ' #86d549', ' #89d548', ' #8bd646', ' #8ed645', ' #90d743', ' #93d741', ' #95d840', ' #98d83e', ' #9bd93c', ' #9dd93b', ' #a0da39', ' #a2da37', ' #a5db36', ' #a8db34', ' #aadc32', ' #addc30', ' #b0dd2f', ' #b2dd2d', ' #b5de2b', ' #b8de29', ' #bade28', ' #bddf26', ' #c0df25', ' #c2df23', ' #c5e021', ' #c8e020', ' #cae11f', ' #cde11d', ' #d0e11c', ' #d2e21b', ' #d5e21a', ' #d8e219', ' #dae319', ' #dde318', ' #dfe318', ' #e2e418', ' #e5e419', ' #e7e419', ' #eae51a', ' #ece51b', ' #efe51c', ' #f1e51d', ' #f4e61e', ' #f6e620', ' #f8e621', ' #fbe723', ' #fde725'], 'min': 0.0, 'max': 9.0, 'opacity': 1.0, 'gamma': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import geemap\n",
    "Map = geemap.Map()\n",
    "geometry = ee.Geometry.Polygon(\n",
    "        [[[-124.58837360718884, 42.24132567361335],\n",
    "          [-124.58837360718884, 32.1623568470788],\n",
    "          [-113.95360798218884, 32.1623568470788],\n",
    "          [-113.95360798218884, 42.24132567361335]]], None, False)\n",
    "Map.addLayer(geometry)\n",
    "Map.centerObject(geometry, 5)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"a120b3b6-1935-4ba6-8edc-543d6ee31215\" style=\"height: auto; width:100%;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " \n",
       "        <script src=\"/static/components/requirejs/require.js\"></script> <!-- Needed in Colab -->\n",
       "        <script>\n",
       "            require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
       "              renderjson.set_show_to_level(1)\n",
       "              document.getElementById('a120b3b6-1935-4ba6-8edc-543d6ee31215').appendChild(renderjson({\"type\": \"Image\", \"bands\": [{\"id\": \"water\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"double\"}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}, {\"id\": \"trees\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"double\"}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}, {\"id\": \"grass\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"double\"}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}, {\"id\": \"flooded_vegetation\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"double\"}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}, {\"id\": \"crops\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"double\"}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}, {\"id\": \"shrub_and_scrub\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"double\"}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}, {\"id\": \"built\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"double\"}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}, {\"id\": \"bare\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"double\"}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}, {\"id\": \"snow_and_ice\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"double\"}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}, {\"id\": \"label\", \"data_type\": {\"type\": \"PixelType\", \"precision\": \"int\", \"min\": 0, \"max\": 255}, \"crs\": \"EPSG:4326\", \"crs_transform\": [1, 0, 0, 0, 1, 0]}]}))\n",
       "            });\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a compsoite dynamic world image over our geometry area. We use a first non-null\n",
    "#  composite which selects the first valid pixel in our specified time range.\n",
    "\n",
    "#  Data preparation - Spatio-temporal filtering\n",
    "dwFiltered = ee.ImageCollection(\"GOOGLE/DYNAMICWORLD/V1\")\\\n",
    ".filterDate('2020-01-01', '2021-01-01')\\\n",
    ".filterBounds(geometry)\\\n",
    ".reduce(ee.Reducer.firstNonNull())\\\n",
    ".rename(ee.List(bands).add('label')).aside(eeprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform inference\n",
    "uqImage = cc.predict(dwFiltered)\n",
    "# Specify visualisation parameters\n",
    "vis_params = {'bands': ['setLength'], 'palette': ['#440154', ' #440256', ' #450457', ' #450559', ' #46075a', ' #46085c', ' #460a5d', ' #460b5e', ' #470d60', ' #470e61', ' #471063', ' #471164', ' #471365', ' #481467', ' #481668', ' #481769', ' #48186a', ' #481a6c', ' #481b6d', ' #481c6e', ' #481d6f', ' #481f70', ' #482071', ' #482173', ' #482374', ' #482475', ' #482576', ' #482677', ' #482878', ' #482979', ' #472a7a', ' #472c7a', ' #472d7b', ' #472e7c', ' #472f7d', ' #46307e', ' #46327e', ' #46337f', ' #463480', ' #453581', ' #453781', ' #453882', ' #443983', ' #443a83', ' #443b84', ' #433d84', ' #433e85', ' #423f85', ' #424086', ' #424186', ' #414287', ' #414487', ' #404588', ' #404688', ' #3f4788', ' #3f4889', ' #3e4989', ' #3e4a89', ' #3e4c8a', ' #3d4d8a', ' #3d4e8a', ' #3c4f8a', ' #3c508b', ' #3b518b', ' #3b528b', ' #3a538b', ' #3a548c', ' #39558c', ' #39568c', ' #38588c', ' #38598c', ' #375a8c', ' #375b8d', ' #365c8d', ' #365d8d', ' #355e8d', ' #355f8d', ' #34608d', ' #34618d', ' #33628d', ' #33638d', ' #32648e', ' #32658e', ' #31668e', ' #31678e', ' #31688e', ' #30698e', ' #306a8e', ' #2f6b8e', ' #2f6c8e', ' #2e6d8e', ' #2e6e8e', ' #2e6f8e', ' #2d708e', ' #2d718e', ' #2c718e', ' #2c728e', ' #2c738e', ' #2b748e', ' #2b758e', ' #2a768e', ' #2a778e', ' #2a788e', ' #29798e', ' #297a8e', ' #297b8e', ' #287c8e', ' #287d8e', ' #277e8e', ' #277f8e', ' #27808e', ' #26818e', ' #26828e', ' #26828e', ' #25838e', ' #25848e', ' #25858e', ' #24868e', ' #24878e', ' #23888e', ' #23898e', ' #238a8d', ' #228b8d', ' #228c8d', ' #228d8d', ' #218e8d', ' #218f8d', ' #21908d', ' #21918c', ' #20928c', ' #20928c', ' #20938c', ' #1f948c', ' #1f958b', ' #1f968b', ' #1f978b', ' #1f988b', ' #1f998a', ' #1f9a8a', ' #1e9b8a', ' #1e9c89', ' #1e9d89', ' #1f9e89', ' #1f9f88', ' #1fa088', ' #1fa188', ' #1fa187', ' #1fa287', ' #20a386', ' #20a486', ' #21a585', ' #21a685', ' #22a785', ' #22a884', ' #23a983', ' #24aa83', ' #25ab82', ' #25ac82', ' #26ad81', ' #27ad81', ' #28ae80', ' #29af7f', ' #2ab07f', ' #2cb17e', ' #2db27d', ' #2eb37c', ' #2fb47c', ' #31b57b', ' #32b67a', ' #34b679', ' #35b779', ' #37b878', ' #38b977', ' #3aba76', ' #3bbb75', ' #3dbc74', ' #3fbc73', ' #40bd72', ' #42be71', ' #44bf70', ' #46c06f', ' #48c16e', ' #4ac16d', ' #4cc26c', ' #4ec36b', ' #50c46a', ' #52c569', ' #54c568', ' #56c667', ' #58c765', ' #5ac864', ' #5cc863', ' #5ec962', ' #60ca60', ' #63cb5f', ' #65cb5e', ' #67cc5c', ' #69cd5b', ' #6ccd5a', ' #6ece58', ' #70cf57', ' #73d056', ' #75d054', ' #77d153', ' #7ad151', ' #7cd250', ' #7fd34e', ' #81d34d', ' #84d44b', ' #86d549', ' #89d548', ' #8bd646', ' #8ed645', ' #90d743', ' #93d741', ' #95d840', ' #98d83e', ' #9bd93c', ' #9dd93b', ' #a0da39', ' #a2da37', ' #a5db36', ' #a8db34', ' #aadc32', ' #addc30', ' #b0dd2f', ' #b2dd2d', ' #b5de2b', ' #b8de29', ' #bade28', ' #bddf26', ' #c0df25', ' #c2df23', ' #c5e021', ' #c8e020', ' #cae11f', ' #cde11d', ' #d0e11c', ' #d2e21b', ' #d5e21a', ' #d8e219', ' #dae319', ' #dde318', ' #dfe318', ' #e2e418', ' #e5e419', ' #e7e419', ' #eae51a', ' #ece51b', ' #efe51c', ' #f1e51d', ' #f4e61e', ' #f6e620', ' #f8e621', ' #fbe723', ' #fde725'], 'min': 0.0, 'max': 9.0}\n",
    "# Visualise set length image i.e., the length of each pixels set. a higher value corresponds to a more uncertain prediction.\n",
    "Map.addLayer(uqImage, vis_params, 'Uncertainty (set Length)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erthy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
